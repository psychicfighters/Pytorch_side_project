{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Pytorch Side Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "sVzHDxKr9TyB",
        "colab_type": "code",
        "outputId": "baa3671a-815c-4446-a82c-57bae7761201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install emoji"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 30kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x61eec000 @  0x7f1c6e2312a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 14.2MB/s \n",
            "\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Installing collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1 torch-1.0.0 torchvision-0.2.1\n",
            "Collecting emoji\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/fb/7586e11ff9205c9be9d11d376fcb6990ec4bdfae0a35663fb1ada7e3c10f/emoji-0.5.1-py3-none-any.whl\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_gDYLzhWsTRn",
        "colab_type": "code",
        "outputId": "09db305b-2147-4f74-c450-31e6780d96e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.50d.txt  glove.6B.zip\tsample_data  tesss.csv\ttrain_emoji.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S7-Vb4f3fCIS",
        "colab_type": "code",
        "outputId": "7780772e-de86-4e9d-fb38-8d698f41369e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "!rm *.*.*00d.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-07 14:23:49--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-01-07 14:23:49--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  20.9MB/s    in 87s     \n",
            "\n",
            "2019-01-07 14:25:17 (9.44 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "30eLK50d9kPv",
        "colab_type": "code",
        "outputId": "86c9b291-447e-4b42-d182-8a9d55b55b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import csv\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "B9ZTIFdR_AVn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "        \n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words_to_index, index_to_words, word_to_vec_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vlXYekhNDlML",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
        "                    \"1\": \":baseball:\",\n",
        "                    \"2\": \":smile:\",\n",
        "                    \"3\": \":disappointed:\",\n",
        "                    \"4\": \":fork_and_knife:\"}\n",
        "\n",
        "def label_to_emoji(label):\n",
        "    \"\"\"\n",
        "    Converts a label (int or string) into the corresponding emoji code (string) ready to be printed\n",
        "    \"\"\"\n",
        "    return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "81muWKkNAtrj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_csv(filename):\n",
        "    phrase = []\n",
        "    emoji = []\n",
        "\n",
        "    with open(filename) as csvDataFile:\n",
        "        csvReader = csv.reader(csvDataFile)\n",
        "\n",
        "        for row in csvReader:\n",
        "            phrase.append(row[0].strip())\n",
        "            emoji.append(row[1].strip())\n",
        "\n",
        "    X = np.asarray(phrase)\n",
        "    Y = np.asarray(emoji, dtype=int)\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IXYpMXvruv-X",
        "colab_type": "code",
        "outputId": "2dbd9323-b1ac-4508-ab96-451fd9412531",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2add5fc4-7389-4bae-91c3-641e8adb09f5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2add5fc4-7389-4bae-91c3-641e8adb09f5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving tesss.csv to tesss.csv\n",
            "Saving train_emoji.csv to train_emoji.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B5yB_n8JDYVK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the dataset using the code below. We split the dataset between training (127 examples) and testing (56 examples)."
      ]
    },
    {
      "metadata": {
        "id": "3ap1vTBqCrNI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, Y_train = read_csv('train_emoji.csv')\n",
        "X_test, Y_test = read_csv('tesss.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Htr8d5E1BuS",
        "colab_type": "code",
        "outputId": "d28163d2-b12c-45be-a923-05605c8712e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "len(X_train), len(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(132, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "UBYlkwd20m8a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for i in range(len(X_train)):\n",
        "#     print(i, X_train[i], label_to_emoji(Y_train[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pyfx-gI1C9Zo",
        "colab_type": "code",
        "outputId": "d42063d9-1ad9-4b1d-ec3b-44fdc93b1c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "maxLen = len(max(X_train, key=len).split())\n",
        "maxLen"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "S33tHp8KDv8S",
        "colab_type": "code",
        "outputId": "6bbcfa42-4679-435d-fa67-1332cc98dc4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "index = 1\n",
        "print(X_train[index], label_to_emoji(Y_train[index]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am proud of your achievements 😄\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BtpZtTr2D8CD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rxEsDoztEtIN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- `word_to_index`: dictionary mapping from words to their indices in the vocabulary (400,001 words, with the valid indices ranging from 0 to 400,000)\n",
        "- `index_to_word`: dictionary mapping from indices to their corresponding words in the vocabulary\n",
        "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation."
      ]
    },
    {
      "metadata": {
        "id": "dC3al0t_Em0s",
        "colab_type": "code",
        "outputId": "4c0c1116-d18a-4371-99ed-ad917ba9ef78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# as a example\n",
        "word = \"cucumber\"\n",
        "index = 289846\n",
        "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
        "print(\"the\", str(index) + \"th word in the vocabulary is\", index_to_word[index])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the index of cucumber in the vocabulary is 113317\n",
            "the 289846th word in the vocabulary is potatos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fFPbrH5lFxRS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert all your training sentences into lists of indices, and then zero-pad all these lists so that their length is the length of the longest sentence."
      ]
    },
    {
      "metadata": {
        "id": "MaYStjNIFvfZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "    \"\"\"\n",
        "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
        "    The output shape should be such that it can be given to `Embedding()`. \n",
        "    \n",
        "    Arguments:\n",
        "    X -- array of sentences (strings), of shape (m, 1)\n",
        "    word_to_index -- a dictionary containing the each word mapped to its index\n",
        "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
        "    \n",
        "    Returns:\n",
        "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[0]                                   # number of training examples\n",
        "    \n",
        "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)\n",
        "    X_indices = np.zeros((m, max_len))\n",
        "    \n",
        "    for i in range(m):                               # loop over training examples\n",
        "        \n",
        "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
        "        sentence_words = X[i].lower().split()\n",
        "        \n",
        "        # Initialize j to -1\n",
        "        j = 0\n",
        "        \n",
        "        # Loop over the words of sentence_words\n",
        "        for w in reversed(sentence_words):\n",
        "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
        "            X_indices[i, j-1] = word_to_index[w]\n",
        "            # decrement j to j - 1\n",
        "            j = j - 1\n",
        "#         for w in sentence_words:\n",
        "#             # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
        "#             X_indices[i, j] = word_to_index[w]\n",
        "#             # decrement j to j + 1\n",
        "#             j = j + 1\n",
        "    \n",
        "    return X_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ghDTAGVFF0B",
        "colab_type": "code",
        "outputId": "177ac9e0-1fd0-4717-853e-117f82c37995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
        "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
        "print(\"X1 =\", X1)\n",
        "print(\"\\nX1_indices =\", X1_indices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
            "\n",
            "X1_indices = [[     0.      0.      0. 155345. 225122.]\n",
            " [     0.      0. 220930. 286375.  69714.]\n",
            " [151204. 192973. 302254. 151349. 394475.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KdTrn-F0QNBK",
        "colab_type": "code",
        "outputId": "67f3a4aa-3188-40ed-dea5-8764448ae554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((132,), (56,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "WDucaBKUQObm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = sentences_to_indices(X_train, word_to_index, maxLen)\n",
        "X_test = sentences_to_indices(X_test, word_to_index, maxLen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyuEfT5wTMOA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(Y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(Y_test))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 4\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VhLQThkSoo2r",
        "colab_type": "code",
        "outputId": "ca6c0f54-b547-4776-96dd-2a122af6679a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x, y = next(iter(train_loader))\n",
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "v6yjPlIG7XPp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for i in range(x.size(0)):\n",
        "#     print(' '.join([index_to_word[int(xx)] for xx in x[i] if xx != 0]), label_to_emoji(int(y[i])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8ROub-bVMcH",
        "colab_type": "code",
        "outputId": "5ac544a1-2481-46bf-f1f0-991f4a2c832b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# First checking if GPU is available\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "print('Training on GPU.') if train_on_gpu else print('No GPU available, training on CPU.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V8BqYQl4VgQh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    \"\"\"\n",
        "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
        "    \n",
        "    Arguments:\n",
        "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
        "\n",
        "    Returns:\n",
        "    embedding_layer -- pretrained layer Keras instance\n",
        "    \"\"\"\n",
        "    \n",
        "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
        "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
        "    \n",
        "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
        "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
        "    \n",
        "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
        "    for word, index in word_to_index.items():\n",
        "        emb_matrix[index, :] = word_to_vec_map[word]    \n",
        "    \n",
        "    weight = torch.FloatTensor(emb_matrix)\n",
        "    embedding_layer = nn.Embedding.from_pretrained(weight.cuda())\n",
        "    embedding_layer.weight.requires_grad=False\n",
        "    return embedding_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YvaQU6yhZ9rH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Emojify(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size, hidden_dim, n_layers, word_to_vec_map, word_to_index, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(Emojify, self).__init__()\n",
        "        \n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # define all layers\n",
        "\n",
        "        self.embedding = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "        embedding_dim = self.embedding.embedding_dim\n",
        "    \n",
        "    \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        pretrained_weight = np.array(pretrained_weight)\n",
        "    \n",
        "    \n",
        "    \n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and logsoftmax layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        x = x.type(torch.cuda.LongTensor)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        \n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # logsoftmax function\n",
        "        logsoftmax_out = self.logsoftmax(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        logsoftmax_out = logsoftmax_out.view(batch_size, -1)\n",
        "        # return last logsoftmax output and hidden state\n",
        "        return logsoftmax_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        hidden = (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_dim).cuda()),\n",
        "                  Variable(torch.zeros(self.n_layers, batch_size, self.hidden_dim).cuda()))\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fguzGTUqK7P7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb_matrix = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "vocab_len  = len(word_to_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fpHjlSthgox-",
        "colab_type": "code",
        "outputId": "dba9577f-31e7-467c-ea05-e8696e83eae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "cell_type": "code",
      "source": [
        "output_size = 5\n",
        "hidden_dim = 128\n",
        "n_layers = 2\n",
        "\n",
        "net = Emojify(output_size, hidden_dim, n_layers, word_to_vec_map, word_to_index,drop_prob=0.5)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-8bd44197b9f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmojify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_vec_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrop_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-129-1099aee16127>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_size, hidden_dim, n_layers, word_to_vec_map, word_to_index, drop_prob)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mpretrained_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab_size' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "nHo8WIegJHgc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "#     break\n",
        "    \n",
        "criterion =  nn.NLLLoss()   \n",
        "optimizer1 = torch.optim.Adam(net.lstm.parameters(),lr=0.001)\n",
        "optimizer2 = torch.optim.Adam(net.fc.parameters(),lr=0.001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fJkRdQJ2hMgF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr=0.01\n",
        "\n",
        "criterion =  nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(filter(lambda x: x.requires_grad, net.parameters()), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t5JPOVIOiqvl",
        "colab_type": "code",
        "outputId": "b69bf057-f224-4b2f-c4a2-1e81b6ece7a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# %%time\n",
        "\n",
        "epochs = 50\n",
        "batch_size=4\n",
        "counter = 0\n",
        "print_every = 50\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        \n",
        "        output, h = net(inputs, h)\n",
        "        \n",
        "        # calculate the loss and perform backprop\n",
        "        labels = labels.type(torch.cuda.LongTensor)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "#         nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer1.step()\n",
        "        optimizer2.step()\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            \n",
        "            net.eval()\n",
        "            with torch.no_grad():\n",
        "                val_h = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                for inputs, labels in test_loader:\n",
        "\n",
        "                    # Creating new variables for the hidden state, otherwise\n",
        "                    # we'd backprop through the entire training history\n",
        "                    val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "                    labels = labels.type(torch.cuda.LongTensor)\n",
        "\n",
        "                    output, val_h = net(inputs, val_h)\n",
        "                    val_loss = criterion(output.squeeze(), labels)\n",
        "\n",
        "                    val_losses.append(val_loss.item())\n",
        "\n",
        "                net.train()\n",
        "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2/50... Step: 50... Loss: 1.079356... Val Loss: 1.531807\n",
            "Epoch: 4/50... Step: 100... Loss: 1.278362... Val Loss: 1.534689\n",
            "Epoch: 5/50... Step: 150... Loss: 1.307775... Val Loss: 1.558298\n",
            "Epoch: 7/50... Step: 200... Loss: 1.417094... Val Loss: 1.539577\n",
            "Epoch: 8/50... Step: 250... Loss: 1.478668... Val Loss: 1.545313\n",
            "Epoch: 10/50... Step: 300... Loss: 1.258510... Val Loss: 1.544250\n",
            "Epoch: 11/50... Step: 350... Loss: 1.374892... Val Loss: 1.531473\n",
            "Epoch: 13/50... Step: 400... Loss: 1.512365... Val Loss: 1.541032\n",
            "Epoch: 14/50... Step: 450... Loss: 1.374421... Val Loss: 1.540887\n",
            "Epoch: 16/50... Step: 500... Loss: 1.505918... Val Loss: 1.540011\n",
            "Epoch: 17/50... Step: 550... Loss: 1.191117... Val Loss: 1.535961\n",
            "Epoch: 19/50... Step: 600... Loss: 1.813581... Val Loss: 1.537650\n",
            "Epoch: 20/50... Step: 650... Loss: 1.392972... Val Loss: 1.548061\n",
            "Epoch: 22/50... Step: 700... Loss: 1.407580... Val Loss: 1.530825\n",
            "Epoch: 23/50... Step: 750... Loss: 1.237919... Val Loss: 1.533456\n",
            "Epoch: 25/50... Step: 800... Loss: 1.223299... Val Loss: 1.544421\n",
            "Epoch: 26/50... Step: 850... Loss: 1.649441... Val Loss: 1.512846\n",
            "Epoch: 28/50... Step: 900... Loss: 1.584097... Val Loss: 1.534746\n",
            "Epoch: 29/50... Step: 950... Loss: 1.590152... Val Loss: 1.535597\n",
            "Epoch: 31/50... Step: 1000... Loss: 1.550073... Val Loss: 1.533903\n",
            "Epoch: 32/50... Step: 1050... Loss: 1.345714... Val Loss: 1.541162\n",
            "Epoch: 34/50... Step: 1100... Loss: 1.773361... Val Loss: 1.538153\n",
            "Epoch: 35/50... Step: 1150... Loss: 1.558849... Val Loss: 1.533166\n",
            "Epoch: 37/50... Step: 1200... Loss: 1.675614... Val Loss: 1.544166\n",
            "Epoch: 38/50... Step: 1250... Loss: 1.562366... Val Loss: 1.524936\n",
            "Epoch: 40/50... Step: 1300... Loss: 1.560900... Val Loss: 1.538034\n",
            "Epoch: 41/50... Step: 1350... Loss: 1.343560... Val Loss: 1.528106\n",
            "Epoch: 43/50... Step: 1400... Loss: 1.753561... Val Loss: 1.524879\n",
            "Epoch: 44/50... Step: 1450... Loss: 1.591746... Val Loss: 1.546690\n",
            "Epoch: 46/50... Step: 1500... Loss: 1.498306... Val Loss: 1.540092\n",
            "Epoch: 47/50... Step: 1550... Loss: 1.578467... Val Loss: 1.531463\n",
            "Epoch: 49/50... Step: 1600... Loss: 1.912361... Val Loss: 1.535651\n",
            "Epoch: 50/50... Step: 1650... Loss: 1.629327... Val Loss: 1.541322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SCKgklhKsi9U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using Dense Layer Only"
      ]
    },
    {
      "metadata": {
        "id": "69hc3D77Ow1v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "E = pretrained_embedding_layer(word_to_vec_map, word_to_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pYsnRMprnMC2",
        "colab_type": "code",
        "outputId": "83a85a61-75c7-48ed-9dc2-3097e8d656b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(50, 5),\n",
        "                     nn.LogSoftmax(dim=1))\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=50, out_features=5, bias=True)\n",
              "  (1): LogSoftmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "srhllohjqFJG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr=0.003\n",
        "\n",
        "criterion = nn.NLLLoss() # nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rOiJt1fwoeK3",
        "colab_type": "code",
        "outputId": "4f951199-7085-4c18-a460-0ebb23a96ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1697
        }
      },
      "cell_type": "code",
      "source": [
        "for z in range(1000):\n",
        "    c = 10\n",
        "    L = 0\n",
        "    for i, j in train_loader:\n",
        "        i = i.type(torch.cuda.LongTensor)\n",
        "        j = j.type(torch.cuda.LongTensor)\n",
        "        i = E(i)\n",
        "        i = i.mean(dim=1)\n",
        "        model.zero_grad()\n",
        "        out = model(i)\n",
        "        loss = criterion(out, j)\n",
        "        L += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if z%c==0:\n",
        "        print(L/len(train_loader))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5956361004800508\n",
            "1.1728925542397932\n",
            "0.9668360605384364\n",
            "0.8361904530814199\n",
            "0.7458668730475686\n",
            "0.6801947120464209\n",
            "0.6299959719181061\n",
            "0.5858768838824648\n",
            "0.5492915736906456\n",
            "0.5218693708831613\n",
            "0.4958112673325972\n",
            "0.47238741769935144\n",
            "0.45135725086385553\n",
            "0.4331042125369563\n",
            "0.4184632924470035\n",
            "0.40348580344156787\n",
            "0.3893981580481385\n",
            "0.37610306116667663\n",
            "0.3628714658094175\n",
            "0.3525622369665088\n",
            "0.34128371558406134\n",
            "0.33214528587731446\n",
            "0.32220733797911444\n",
            "0.3132116568811012\n",
            "0.30486777063572046\n",
            "0.30037839801022503\n",
            "0.29106539713613916\n",
            "0.2838682220740752\n",
            "0.2772464968941428\n",
            "0.27000878977053094\n",
            "0.2637331052259965\n",
            "0.261217376499465\n",
            "0.254329598311222\n",
            "0.24677884578704834\n",
            "0.24318666394912836\n",
            "0.2360672688845432\n",
            "0.23111939204461646\n",
            "0.22677865985668066\n",
            "0.22521896886103082\n",
            "0.21899127689274875\n",
            "0.2143439081582156\n",
            "0.21106533977118405\n",
            "0.20867258310317993\n",
            "0.20282769112875967\n",
            "0.2006824237830711\n",
            "0.19736430410182837\n",
            "0.19238117156606732\n",
            "0.1902822716669603\n",
            "0.1865366299947103\n",
            "0.18525923066066974\n",
            "0.18361716288508792\n",
            "0.1778845371622028\n",
            "0.17560435786391748\n",
            "0.1733000147523302\n",
            "0.1708935056671952\n",
            "0.1672235212542794\n",
            "0.16599622323657526\n",
            "0.16292471370913766\n",
            "0.159929531993288\n",
            "0.15776985612782565\n",
            "0.1557254714496208\n",
            "0.15494687855243683\n",
            "0.15233102215058875\n",
            "0.15113057602535596\n",
            "0.14844323604395895\n",
            "0.14636544702631055\n",
            "0.14518568687366717\n",
            "0.1433639625708262\n",
            "0.14151218398050827\n",
            "0.13854414495554837\n",
            "0.13739093144734701\n",
            "0.13461662061286694\n",
            "0.13276436066988742\n",
            "0.13237006284973837\n",
            "0.12959655487176144\n",
            "0.13037530129606073\n",
            "0.1267501978260098\n",
            "0.12538113287000946\n",
            "0.1248555038914536\n",
            "0.12331365590745752\n",
            "0.12074329139608325\n",
            "0.11925717646425421\n",
            "0.12061230612523628\n",
            "0.11654007389689937\n",
            "0.11550657676927971\n",
            "0.11488557855288188\n",
            "0.11384882213491382\n",
            "0.11300311847166582\n",
            "0.1113448937733968\n",
            "0.11097913574088704\n",
            "0.10816926215634201\n",
            "0.10609255821415872\n",
            "0.10596386862523628\n",
            "0.10518650665427699\n",
            "0.1032899735551892\n",
            "0.1028584201227535\n",
            "0.10116170346736908\n",
            "0.10055922468503316\n",
            "0.10015802311174797\n",
            "0.09793448267561017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iF1299gTqQ9L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}